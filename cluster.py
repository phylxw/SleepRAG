import os
import json
import re
import time
import numpy as np
import torch
import matplotlib.pyplot as plt 
from typing import List, Dict
from sentence_transformers import SentenceTransformer
from sklearn.cluster import AgglomerativeClustering, KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.manifold import TSNE 
from sklearn.decomposition import PCA 
from transformers import AutoModelForCausalLM, AutoTokenizer
import umap

# Hydra
import hydra
from omegaconf import DictConfig

# ================= å…¨å±€å˜é‡ (ä¿æŒåŸé€»è¾‘) =================
GLOBAL_MODEL = None
GLOBAL_TOKENIZER = None
GLOBAL_SGLANG_CLIENT = None
# =============== 0. å·¥å…·å‡½æ•° ===============
def clean_special_chars(text: str) -> str:
    if not isinstance(text, str): return text
    return text.replace('\u2028', ' ').replace('\u2029', ' ')

def normalize_text(x: str) -> str:
    x = x.lower()
    x = re.sub(r"\d+(\.\d+)?", " <num> ", x) 
    x = re.sub(r"\s+", " ", x).strip()
    return x

def import_torch_and_check_gpu():
    try: return torch.cuda.is_available()
    except: return False

# =============== 1. LLM åˆå§‹åŒ–ä¸è°ƒç”¨ ===============
def init_llm(cfg: DictConfig):
    global GLOBAL_MODEL, GLOBAL_TOKENIZER, GLOBAL_SGLANG_CLIENT
    
    model_source = cfg.model.source
    
    if model_source == "gemini":
        import google.generativeai as genai
        api_key = os.environ.get("GEMINI_API_KEY")
        if api_key:
            genai.configure(api_key=api_key)
            print(f"ğŸ¤– [Init] Gemini API ({cfg.model.gemini_name}) å·²é…ç½®")
        else:
            print("âš ï¸ [Init] æœªæ£€æµ‹åˆ° GEMINI_API_KEYï¼ŒGemini æ¨¡å¼å¯èƒ½æ— æ³•å·¥ä½œ")
            
    elif model_source == "huggingface":
        hf_name = cfg.model.hf_name
        print(f"ğŸ“¥ [Init] æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹: {hf_name} ...")
        try:
            GLOBAL_TOKENIZER = AutoTokenizer.from_pretrained(hf_name, trust_remote_code=True)
            GLOBAL_MODEL = AutoModelForCausalLM.from_pretrained(
                hf_name,
                device_map="auto",
                torch_dtype="auto",
                trust_remote_code=True
            ).eval()
            print("âœ… [Init] æœ¬åœ°æ¨¡å‹åŠ è½½å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ [Init] æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ æç¤º: è¯·ç¡®ä¿å·²é€šè¿‡ `huggingface-cli login` ç™»å½•æˆ–æ£€æŸ¥ç½‘ç»œ")

    elif model_source == "sglang":
        try:
            from openai import OpenAI
            # ä»é…ç½®è¯»å– URLï¼Œé»˜è®¤æœ¬åœ°ç«¯å£
            api_url = cfg.model.get("sglang_api_url", "http://127.0.0.1:30000/v1")
            api_key = "EMPTY" # SGLang æœ¬åœ°éƒ¨ç½²ä¸éœ€è¦çœŸå® Key
            
            GLOBAL_SGLANG_CLIENT = OpenAI(base_url=api_url, api_key=api_key)
            print(f"âœ… [Init] SGLang Client å·²è¿æ¥è‡³ {api_url}")
        except ImportError:
            print("âŒ [Init] ç¼ºå°‘ openai åº“ï¼Œè¯·è¿è¡Œ `pip install openai`")

def call_llm(prompt: str, cfg: DictConfig) -> str:
    model_source = cfg.model.source
    
    if model_source == "gemini":
        import google.generativeai as genai
        if not os.environ.get("GEMINI_API_KEY"): return "Skipped (No Key)"
        model = genai.GenerativeModel(cfg.model.gemini_name) 
        try:
            print("  ğŸ¤– [Gemini] æ­£åœ¨æ€è€ƒ...", end="", flush=True)
            resp = model.generate_content(prompt)
            print(" å®Œæˆ!")
            return clean_special_chars(resp.text.strip())
        except Exception as e:
            print(f"\nâŒ [Gemini Error]: {e}")
            time.sleep(1)
            return "Unknown Topic"

    elif model_source == "huggingface":
        if GLOBAL_MODEL is None:
            return "Skipped (Model Not Loaded)"
        try:
            print("  ğŸš€ [Local] æ­£åœ¨æ¨ç†...", end="", flush=True)
            messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ]
            text = GLOBAL_TOKENIZER.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            model_inputs = GLOBAL_TOKENIZER([text], return_tensors="pt").to(GLOBAL_MODEL.device)

            with torch.no_grad():
                generated_ids = GLOBAL_MODEL.generate(model_inputs.input_ids, max_new_tokens=50, do_sample=False)
            
            generated_ids = [
                output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
            ]
            response = GLOBAL_TOKENIZER.batch_decode(generated_ids, skip_special_tokens=True)[0]
            print(" å®Œæˆ!")
            return clean_special_chars(response.strip())
        except Exception as e:
            print(f"\nâŒ [Local Error]: {e}")
            return "Unknown Topic"

    elif model_source == "sglang":
        if GLOBAL_SGLANG_CLIENT is None:
            return "Skipped (Client Not Initialized)"
        
        # è·å–æ¨¡å‹åï¼Œé»˜è®¤ Qwen
        model_name = cfg.model.get("sglang_model_name", "Qwen/Qwen3-4B-Instruct-2507")
        
        try:
            print("  ğŸš€ [SGLang] æ­£åœ¨æ¨ç†...", end="", flush=True)
            resp = GLOBAL_SGLANG_CLIENT.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0, # èšç±»å‘½åæœ€å¥½ç¡®å®šæ€§é«˜ä¸€ç‚¹
                max_tokens=50    # åå­—ä¸éœ€è¦å¤ªé•¿
            )
            # æå–å†…å®¹
            content = resp.choices[0].message.content
            print(" å®Œæˆ!")
            return clean_special_chars(content.strip())
        except Exception as e:
            print(f"\nâŒ [SGLang Error]: {e}")
            return "Unknown Topic"

    return "Unknown Config"

# =============== 2. åŸºç¡€ IO ===============
def load_questions(jsonl_path: str):
    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ–‡ä»¶: {jsonl_path}...")
    if not os.path.exists(jsonl_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {jsonl_path}")
        return [], []

    ids, questions = [], []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip(): continue
            try:
                obj = json.loads(line)
            except json.JSONDecodeError: continue
            
            # å…¼å®¹ pre.py çš„è¾“å‡ºæ ¼å¼
            content = obj.get("contents", "")
            if "Question:" in content:
                # å°è¯•åˆ†ç¦» Question å’Œ Answerï¼Œåªèšç±» Question éƒ¨åˆ†
                q_part = content.split("Answer:")[0].replace("Question:", "").strip()
                # å¦‚æœ split å¤±è´¥ï¼ˆä¾‹å¦‚æ²¡æœ‰ Answer: æ ‡ç­¾ï¼‰ï¼Œè¿™è¡Œä»£ç ä¼šä¿ç•™åŸæ ·
                if not q_part and content: q_part = content 
            else:
                q_part = content
            
            # ä½¿ç”¨ memory_id (pre.py ç”Ÿæˆçš„)
            mid = obj.get("memory_id", obj.get("id"))
            
            ids.append(str(mid))
            questions.append(clean_special_chars(q_part))
            
    print(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(questions)} æ¡æ•°æ®")
    return ids, questions

# =============== 3. ä¸»æµç¨‹ï¼šembedding + è‡ªåŠ¨èšç±» ===============
def build_embeddings(questions: List[str], model_name: str) -> np.ndarray:
    print(f"ğŸš€ æ­£åœ¨è®¡ç®— Embeddings ({model_name})...")
    device = "cuda" if import_torch_and_check_gpu() else "cpu"
    print(f"   >>> ä½¿ç”¨è®¾å¤‡: {device}")
    
    model = SentenceTransformer(model_name, device=device)
    q_norm = [normalize_text(q) for q in questions]
    emb = model.encode(q_norm, batch_size=32, show_progress_bar=True, normalize_embeddings=True)
    return np.asarray(emb)

def preprocess_embeddings_pca(embeddings: np.ndarray, n_components: int) -> np.ndarray:
    """
    ğŸ”¥ PCA é™ç»´å»å™ª
    """
    print(f"ğŸ§¹ æ­£åœ¨æ‰§è¡Œ PCA é¢„å¤„ç† (é™ç»´: {embeddings.shape[1]} -> {n_components})...")
    if embeddings.shape[0] < n_components:
        print(f"âš ï¸ æ ·æœ¬æ•° ({embeddings.shape[0]}) å°‘äºç›®æ ‡ç»´åº¦ ({n_components})ï¼Œè·³è¿‡ PCA é¢„å¤„ç†ã€‚")
        return embeddings
    
    pca = PCA(n_components=n_components)
    reduced = pca.fit_transform(embeddings)
    
    explained_variance = np.sum(pca.explained_variance_ratio_)
    print(f"   >>> ä¿ç•™æ–¹å·®æ¯”ä¾‹: {explained_variance:.2%}")
    return reduced

def cluster_questions_auto(embeddings: np.ndarray, cfg: DictConfig) -> np.ndarray:
    method = cfg.cluster.method
    
    if method == "kmeans":
        n_clusters = cfg.cluster.kmeans_n_clusters
        print(f"ğŸ¤– æ­£åœ¨æ‰§è¡Œ K-Means èšç±» (N_Clusters={n_clusters})...")
        model = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
        labels = model.fit_predict(embeddings)
        print(f"âœ¨ K-Means èšç±»å®Œæˆï¼å…±ç”Ÿæˆ {n_clusters} ä¸ªç±»åˆ«ã€‚")
        return labels
        
    elif method == "agglomerative":
        threshold = cfg.cluster.distance_threshold
        print(f"ğŸ¤– æ­£åœ¨æ‰§è¡Œå±‚æ¬¡èšç±» Agglomerative (Distance Threshold={threshold})...")
        model = AgglomerativeClustering(
            n_clusters=None, 
            distance_threshold=threshold,
            metric='euclidean', 
            linkage='ward'
        )
        labels = model.fit_predict(embeddings)
        n_clusters_found = len(set(labels))
        print(f"âœ¨ å±‚æ¬¡èšç±»å®Œæˆï¼æ¨¡å‹è‡ªåŠ¨å‘ç°äº† {n_clusters_found} ä¸ªé¢˜å‹ç±»åˆ«ã€‚")
        return labels
    
    else:
        raise ValueError(f"æœªçŸ¥çš„èšç±»æ–¹æ³•: {method}")

# =============== 4. ç»Ÿè®¡ç»˜å›¾ & å…³é”®è¯ & é™ç»´å¯è§†åŒ– ===============

def plot_cluster_stats(labels: np.ndarray, save_path: str, method_name: str):
    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆç»Ÿè®¡å›¾è¡¨...")
    unique_labels, counts = np.unique(labels, return_counts=True)
    
    singleton_mask = counts == 1
    num_singletons = np.sum(singleton_mask)
    
    valid_mask = ~singleton_mask
    valid_labels = unique_labels[valid_mask]
    valid_counts = counts[valid_mask]
    
    print(f"   - æ€»èšç±»æ•°: {len(unique_labels)}")
    print(f"   - å­¤ç«‹èšç±»æ•° (Size=1): {num_singletons}")
    print(f"   - æœ‰æ•ˆèšç±»æ•° (Size>1): {len(valid_labels)}")
    
    if len(valid_counts) == 0:
        print("   âš ï¸ æ²¡æœ‰åŒ…å«å¤šä¸ªé—®é¢˜çš„èšç±»ï¼Œè·³è¿‡ç»˜å›¾ã€‚")
        return

    sorted_indices = np.argsort(valid_counts)[::-1]
    sorted_plot_labels = valid_labels[sorted_indices]
    sorted_plot_counts = valid_counts[sorted_indices]
    
    plt.figure(figsize=(12, 6))
    x_ticks = [str(lbl) for lbl in sorted_plot_labels]
    plt.bar(x_ticks, sorted_plot_counts, color='steelblue', edgecolor='black', alpha=0.8)
    plt.xlabel('Cluster ID', fontsize=12)
    plt.ylabel('Number of Questions', fontsize=12)
    plt.title(f'Cluster Size Distribution (Descending)\nMethod: {method_name}', fontsize=14)
    if len(x_ticks) > 30: 
        plt.xticks(rotation=90, fontsize=8)
    else: 
        plt.xticks(rotation=0)
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.savefig(save_path)
    print(f"ğŸ–¼ï¸ å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")

def plot_dimensionality_reduction(embeddings: np.ndarray, labels: np.ndarray, cfg: DictConfig, save_path: str):
    method = cfg.cluster.vis_method
    
    print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆ {method.upper()} èšç±»åˆ†å¸ƒå›¾...")
    if embeddings.shape[0] < 2:
        print("âš ï¸ æ•°æ®ç‚¹å¤ªå°‘ï¼Œè·³è¿‡å¯è§†åŒ–ã€‚")
        return

    reducer = None
    
    # --- 1. é€‰æ‹©ç®—æ³• ---
    if method == "tsne":
        n_samples = embeddings.shape[0]
        # è¯»å– config å‚æ•°
        perplexity_val = min(cfg.cluster.tsne_perplexity, n_samples - 1) if n_samples > 1 else 1
        print(f"   >>> è¿è¡Œ t-SNE (perplexity={perplexity_val})...")
        
        reducer = TSNE(
            n_components=2, 
            perplexity=perplexity_val, 
            random_state=42, 
            init='pca', 
            learning_rate='auto'
        )
        
    elif method == "pca":
        print(f"   >>> è¿è¡Œ PCA (Linear)...")
        reducer = PCA(n_components=2)
        
    elif method == "umap":
        if umap is None:
            print("âŒ æœªæ£€æµ‹åˆ° UMAP åº“ã€‚è¯·è¿è¡Œ `pip install umap-learn` å®‰è£…ã€‚")
            print("   (å°†è‡ªåŠ¨å›é€€åˆ° t-SNE)")
            # é€’å½’è°ƒç”¨å›é€€
            cfg.cluster.vis_method = "tsne"
            return plot_dimensionality_reduction(embeddings, labels, cfg, save_path)
        print(f"   >>> è¿è¡Œ UMAP...")
        reducer = umap.UMAP(n_components=2, random_state=42)
        
    else:
        print(f"âŒ æœªçŸ¥çš„å¯è§†åŒ–æ–¹æ³•: {method}")
        return

    # --- 2. é™ç»´ ---
    reduced_emb = reducer.fit_transform(embeddings)

    # --- 3. ç»˜å›¾ ---
    plt.figure(figsize=(12, 10))
    scatter = plt.scatter(
        reduced_emb[:, 0], 
        reduced_emb[:, 1], 
        c=labels, 
        cmap='nipy_spectral', 
        s=15, 
        alpha=0.6,
        edgecolor='none'
    )
    
    plt.colorbar(scatter, label='Cluster ID')
    plt.title(f'{method.upper()} Visualization\n(Cluster: {cfg.cluster.method}, Preprocess: {cfg.cluster.enable_pca_preprocess})', fontsize=15)
    plt.xlabel(f'{method.upper()} Dimension 1')
    plt.ylabel(f'{method.upper()} Dimension 2')
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.tight_layout()
    
    plt.savefig(save_path, dpi=300)
    print(f"ğŸ–¼ï¸ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")

def tfidf_keywords_per_cluster(questions, cluster_labels, max_features=5000, top_k=10):
    print("ğŸ” æå–å…³é”®è¯...")
    q_norm = [normalize_text(q) for q in questions]
    vectorizer = TfidfVectorizer(max_df=0.9, min_df=3, max_features=max_features, stop_words="english")
    try:
        X = vectorizer.fit_transform(q_norm)
        vocab = np.array(vectorizer.get_feature_names_out())

        cluster_keywords = {}
        for cid in np.unique(cluster_labels):
            idx = np.where(cluster_labels == cid)[0]
            if len(idx) == 0: continue
            tfidf_mean = np.asarray(X[idx].mean(axis=0)).ravel()
            top_idx = tfidf_mean.argsort()[::-1][:top_k]
            cluster_keywords[cid] = vocab[top_idx].tolist()
        return cluster_keywords
    except ValueError:
        print("âš ï¸ æ ·æœ¬å¤ªå°‘æˆ–è¯æ±‡é‡ä¸è¶³ï¼Œè·³è¿‡å…³é”®è¯æå–")
        return {}

def llm_label_cluster(cid, questions, cluster_labels, cluster_keywords, cfg: DictConfig, max_examples=5):
    idx = np.where(cluster_labels == cid)[0]
    examples_idx = np.random.choice(idx, min(len(idx), max_examples), replace=False)
    examples = [questions[i] for i in examples_idx]
    kw = ", ".join(cluster_keywords.get(cid, []))

    prompt = f"""You are a Math Education Expert.
I have automatically grouped similar math problems together.
Keywords: [{kw}]
Examples:
{chr(10).join(f"- {q}" for q in examples)}

Task: Provide a **very short category name** (3-6 words) for this specific math problem type.
Output ONLY the category name.
"""
    # ä¼ å…¥ cfg è°ƒç”¨ LLM
    label = call_llm(prompt, cfg)
    return label.replace("\n", "").replace('"', "").strip()

# =============== Main (Hydra Integrated) ===============

@hydra.main(version_base=None, config_path="conf", config_name="config")
def cluster(cfg: DictConfig):
    
    # 0. åˆå§‹åŒ–
    init_llm(cfg)

    # 1. è·¯å¾„æ˜ å°„
    input_file = cfg.paths.freq_file  # ä» pre.py çš„è¾“å‡ºæ–‡ä»¶è¯»
    output_file = cfg.paths.cluster_output
    summary_file = cfg.paths.cluster_summary
    plot_file = cfg.paths.cluster_plot
    vis_plot_file = cfg.paths.cluster_vis

    ids, questions = load_questions(input_file)
    if not ids: return

    # 2. Embedding
    embeddings = build_embeddings(questions, model_name=cfg.model.embedding_name)
    
    # ğŸ”¥ 2.1 é¢„å¤„ç† (PCA)
    if cfg.cluster.enable_pca_preprocess:
        embeddings = preprocess_embeddings_pca(embeddings, n_components=cfg.cluster.pca_preprocess_dims)

    # 3. èšç±»
    labels = cluster_questions_auto(embeddings, cfg)

    # 4. ç»Ÿè®¡ç”»å›¾
    plot_cluster_stats(labels, save_path=plot_file, method_name=cfg.cluster.method)
    
    # 5. é™ç»´å¯è§†åŒ– (t-SNE/PCA/UMAP)
    plot_dimensionality_reduction(embeddings, labels, cfg, save_path=vis_plot_file)

    # 6. åˆ†æå…³é”®è¯ä¸ä¿å­˜
    keywords_map = tfidf_keywords_per_cluster(questions, labels)
    
    print("\n" + "="*20 + " èšç±»ç»“æœåˆ†æ " + "="*20)
    cluster_labels_text = {}
    
    unique, counts = np.unique(labels, return_counts=True)
    sorted_clusters = sorted(zip(unique, counts), key=lambda x: x[1], reverse=True)
    
    print(f"ğŸ“Š æ€»å…±å‘ç° {len(sorted_clusters)} ä¸ªèšç±»ã€‚")
    print("   (ä»…å±•ç¤ºå¹¶å‘½ååŒ…å«é¢˜ç›®æœ€å¤šçš„å‰ 10 ä¸ªèšç±»)\n")

    for cid, count in sorted_clusters[:10]:
        print(f"\nğŸ·ï¸ åˆ†æ Cluster {cid} (åŒ…å« {count} é¢˜)...")
        label_text = llm_label_cluster(cid, questions, labels, keywords_map, cfg)
        cluster_labels_text[cid] = label_text
        print(f"   >>> é¢˜å‹: {label_text}")
        print(f"   >>> å…³é”®è¯: {keywords_map.get(cid, [])}")
        if cfg.model.source == "gemini": time.sleep(2)

    print(f"\nğŸ’¾ ä¿å­˜è¯¦ç»†ç»“æœåˆ° {output_file}...")
    with open(output_file, "w", encoding="utf-8") as f:
        for qid, q, cid in zip(ids, questions, labels):
            obj = {
                "id": qid,
                "question": q,
                "cluster_id": int(cid),
                "cluster_label": cluster_labels_text.get(int(cid), f"Cluster {cid}"),
                "cluster_keywords": keywords_map.get(int(cid), [])
            }
            f.write(json.dumps(obj, ensure_ascii=False) + "\n")
            
    print(f"ğŸ’¾ ä¿å­˜èšç±»æ‘˜è¦åˆ° {summary_file}...")
    cluster_aggregation = {}
    for qid, cid in zip(ids, labels):
        cid_int = int(cid)
        if cid_int not in cluster_aggregation:
            cluster_aggregation[cid_int] = {
                "cluster_id": cid_int,
                "cluster_label": cluster_labels_text.get(cid_int, f"Cluster {cid_int}"),
                "memory_ids": []
            }
        cluster_aggregation[cid_int]["memory_ids"].append(qid)
    
    with open(summary_file, "w", encoding="utf-8") as f:
        for cid in sorted(cluster_aggregation.keys()):
            f.write(json.dumps(cluster_aggregation[cid], ensure_ascii=False) + "\n")
            
    print("âœ… å…¨éƒ¨å®Œæˆï¼")

if __name__ == "__main__":
    cluster()