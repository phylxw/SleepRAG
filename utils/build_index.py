from datasets import load_dataset
from huggingface_hub import snapshot_download
from omegaconf import DictConfig, OmegaConf
import os
import json
import tqdm
import bm25s

def build_index(corpus_file: str, index_dir: str):
    """æ„å»º BM25 ç´¢å¼•"""

    print(f"ğŸ”¨ [Index] æ­£åœ¨ä¸º {corpus_file} æ„å»º BM25 ç´¢å¼•...")
    corpus_texts = []
    # ä½¿ç”¨ bm25s åº“
    with open(corpus_file, "r", encoding="utf-8") as f:
        for line in f:
            corpus_texts.append(json.loads(line)['contents'])
    
    corpus_tokens = bm25s.tokenize(corpus_texts)
    retriever_builder = bm25s.BM25()
    retriever_builder.index(corpus_tokens)
    retriever_builder.save(index_dir)
    
    # FlashRAG è¦æ±‚çš„é¢å¤–æ–‡ä»¶
    with open(os.path.join(index_dir, "stopwords.tokenizer.json"), "w") as f:
        json.dump([], f)
    with open(os.path.join(index_dir, "vocab.tokenizer.json"), "w") as f:
        vocab = corpus_tokens.vocab
        # å…¼å®¹æ€§å¤„ç†
        json.dump({"word_to_id": vocab, "stem_to_sid": vocab, "word_to_stem": {k: k for k in vocab}}, f)
    print("âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")