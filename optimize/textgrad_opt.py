import os
import re
import uuid
import logging
from typing import List, Dict, Set, Any, Optional
from dataclasses import dataclass, field

# å‡è®¾å·¥å…·åº“è·¯å¾„ä¸å˜
from tools.optimize.callllm import call_llm_batch
from tools.optimize.callexpert import call_expert_batch
from utils.opt.toolfunction import _extract_single_memory, _basic_guard

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("ICML_WarRoom")

@dataclass
class OptimizationTask:
    """è¿½è¸ªå•ä¸ªè®°å¿†çš„ä¼˜åŒ–çŠ¶æ€"""
    mid: str
    original_content: str
    stats: Dict
    # è¯Šæ–­é˜¶æ®µ
    diagnosis_prompt: str = ""
    expert_action: str = "WAITING" # REFINE, REPLACE, EXPAND
    expert_advice: str = ""
    # æ‰§è¡Œé˜¶æ®µ
    student_prompt: str = ""
    generated_content: str = ""
    # è¯„ä¼°é˜¶æ®µ
    judge_verdict: str = "PENDING"
    judge_feedback: str = ""
    retry_count: int = 0
    # ç»“æœ
    final_accepted_content: Optional[str] = None
    # ğŸ”¥ [æ–°å¢] ç”¨äº EXPAND é€»è¾‘
    is_new_node: bool = False 
    parent_id: Optional[str] = None

class TextGradOptimizer:
    def __init__(self, cfg, memories, memory_stats, log_path):
        self.cfg = cfg
        self.memories = memories
        self.memory_stats = memory_stats
        self.log_path = log_path
        self.batch_size = cfg.optimizer.llm_batch_size
        self.max_retries = cfg.parameters.get("max_retries", 2)
        
        # é¢„ç¼–è¯‘æ­£åˆ™
        # å…¼å®¹ä¸¤ç§æ ¼å¼ï¼šæ—¢èƒ½åŒ¹é… \box{EXPAND} ä¹Ÿèƒ½åŒ¹é… Action: EXPAND
        self.action_re = re.compile(r'(?:\\box\{|Action:\s*)(REFINE|EXPAND|REPLACE|CREATE)', re.IGNORECASE)
        
        # å…¼å®¹ä¸¤ç§æ ¼å¼ï¼šæ—¢èƒ½åŒ¹é… \advice{...} ä¹Ÿèƒ½åŒ¹é… Advice: ...
        # æ³¨æ„ï¼šAdvice: åé¢ç›´åˆ°æ–‡æœ¬ç»“æŸéƒ½ç®—å»ºè®®
        self.advice_re = re.compile(r'(?:\\advice\{|Advice:\s*)(.*?)(?:\}|(?=$))', re.DOTALL | re.IGNORECASE)
        self.verdict_re = re.compile(r"Verdict:\s*(PASS|FAIL)", re.IGNORECASE)

        # æ¸…ç©ºæ—¥å¿—æ–‡ä»¶å¤´
        with open(self.log_path, "a", encoding="utf-8") as f:
            f.write(f"\n\n{'='*20} New Optimization Session {'='*20}\n")

    def log(self, msg):
        """åŒå†™æ—¥å¿—"""
        print(msg)
        with open(self.log_path, "a", encoding="utf-8") as f:
            f.write(str(msg) + "\n")

    def run(self, target_ids: List[str], to_delete_ids: Set[str]) -> Set[str]:
        """ä¸»å…¥å£"""
        # 1. è¿‡æ»¤æœ‰æ•ˆID
        valid_ids = [mid for mid in target_ids if mid in self.memories and mid not in to_delete_ids]
        self.log(f"ğŸ¯ å¾…ä¼˜åŒ– {len(valid_ids)} æ¡è®°å¿†")
        
        optimized_ids = set()

        # 2. Batch Loop
        for i in range(0, len(valid_ids), self.batch_size):
            chunk_ids = valid_ids[i : i + self.batch_size]
            self.log(f"\nğŸš€ Processing Batch {i//self.batch_size + 1} ({len(chunk_ids)} items)")
            
            # åˆå§‹åŒ–ä»»åŠ¡å¯¹è±¡
            tasks = self._init_tasks(chunk_ids)
            
            # Phase 1: Expert Diagnosis (è¯Šæ–­)
            # è¿™ä¸€æ­¥ä¼šå¡«å…… tasks é‡Œçš„ expert_action å’Œ expert_advice
            self._batch_diagnose(tasks)
            
            # Phase 2: Student Execution (æ‰§è¡Œ)
            # ğŸ”¥ [æ ¸å¿ƒä¿®æ”¹] è¿™é‡Œä¼šå¤„ç† EXPANDï¼Œå¦‚æœåˆ†è£‚ï¼Œä¼šè¿”å›æ–°äº§ç”Ÿçš„ tasks
            new_tasks = self._batch_execute_and_expand(tasks)
            
            # å°†åˆ†è£‚å‡ºæ¥çš„æ–°ä»»åŠ¡åŠ å…¥å½“å‰å¾…è¯„ä¼°åˆ—è¡¨
            if new_tasks:
                self.log(f"âœ¨ [EXPAND Triggered] Added {len(new_tasks)} new split-nodes to current batch.")
                tasks.extend(new_tasks)

            # Phase 3: Judge Evaluation & Retry Loop (è¯„ä¼°ä¸ä¿®æ­£)
            # è¿™ä¸€æ­¥ä¼šå¡«å…… final_accepted_content
            self._batch_evaluate_loop(tasks)
            
            # Phase 4: Commit (æäº¤)
            # è¿™ä¸€æ­¥ä¼šå°† final_accepted_content å†™å› self.memories
            batch_success_ids = self._commit_changes(tasks)
            optimized_ids.update(batch_success_ids)
            
        return optimized_ids

    def _init_tasks(self, mids) -> List[OptimizationTask]:
        tasks = []
        for mid in mids:
            rec = self.memories[mid]
            tasks.append(OptimizationTask(
                mid=mid,
                original_content=rec.get("contents", ""),
                stats=self.memory_stats.get(mid, {})
            ))
        return tasks

    # --------------------------------------------------------------------------
    # Phase 1: Diagnosis (Expert)
    # --------------------------------------------------------------------------
    def _batch_diagnose(self, tasks: List[OptimizationTask]):
        prompts = []
        for task in tasks:
            neg_queries = task.stats.get('neg_queries', [])
            
            if not neg_queries:
                # æ— é”™é¢˜æ¨¡å¼ -> æ¶¦è‰²
                prompt = self.cfg.optimizer.prompts.low_grad_polish.format(
                    content=task.original_content
                )
            else:
                # é”™é¢˜æ¨¡å¼ -> ä¸“å®¶è¯Šæ–­
                top_k_negs = "\n".join([f"- {q}" for q in neg_queries[:3]])
                prompt = self.cfg.optimizer.prompts.low_grad_expert.format(
                    content=task.original_content,
                    neg_queries=top_k_negs
                )
            
            task.diagnosis_prompt = prompt
            prompts.append(prompt)

        self.log(f"ğŸ§  [Expert] Diagnosing {len(prompts)} memories...")
        outputs = call_expert_batch(prompts, self.cfg)

        for task, out in zip(tasks, outputs):
            if not out: continue
            # è§£æ Action
            m_act = self.action_re.search(out)
            task.expert_action = m_act.group(1) if m_act else "REFINE" 
            
            # è§£æ Advice/Gradient
            m_adv = self.advice_re.search(out)
            gradient = m_adv.group(1).strip() if m_adv else out.strip()
            task.expert_advice = gradient
            
            # ğŸ”¥ [æ—¥å¿—å¢å¼º] æ‰“å°å…·ä½“æ¢¯åº¦ï¼Œå°±åƒåŸæ¥é‚£æ ·
            preview = gradient[:60] + "..." if len(gradient) > 60 else gradient
            self.log(f"  -> ID:{task.mid[:6]} | Action: {task.expert_action}")
            self.log(f"     Gradient: {preview}")

    # --------------------------------------------------------------------------
    # Phase 2: Execution (Student) - [å« EXPAND é€»è¾‘]
    # --------------------------------------------------------------------------
    def _batch_execute_and_expand(self, tasks: List[OptimizationTask]) -> List[OptimizationTask]:
        """
        æ ¹æ®ä¸“å®¶å»ºè®®ï¼Œç”Ÿæˆ Student Promptã€‚
        å¦‚æœæ˜¯ EXPANDï¼Œä¼šç”Ÿæˆä¸¤ä¸ª Promptï¼š
          1. ä¿®æ”¹å½“å‰ä»»åŠ¡ (Refine)
          2. åˆ›å»ºæ–°ä»»åŠ¡ (Create New) -> è¿”å›è¿™ä¸ªæ–°ä»»åŠ¡å¯¹è±¡åˆ—è¡¨
        """
        prompts = []
        active_tasks = [] # è®°å½•å“ªäº›ä»»åŠ¡å‘èµ·äº†è¯·æ±‚ï¼Œç”¨äºå›å¡« output
        new_spawned_tasks = [] # å­˜å‚¨ EXPAND äº§ç”Ÿçš„æ–°ä»»åŠ¡

        for task in tasks:
            if task.expert_action == "WAITING": continue
            
            neg_text = "\n".join(task.stats.get('neg_queries', [])[:3])
            gradient = task.expert_advice

            # --- åˆ†å‘é€»è¾‘ ---
            if task.expert_action == "EXPAND":
                # ğŸ”¥ [å¤æ´» EXPAND é€»è¾‘]
                # 1. ä»»åŠ¡Aï¼šä¼˜åŒ–æ—§è®°å¿† (Refine Old)
                p_old = self.cfg.optimizer.prompts.appgrad_low_refine.format(
                    content=task.original_content, 
                    gradient=f"Keep the general definition, but distinguish from new concept. Advice: {gradient}"
                )
                task.student_prompt = p_old
                prompts.append(p_old)
                active_tasks.append(task)

                # 2. ä»»åŠ¡Bï¼šåˆ›å»ºæ–°è®°å¿† (Create New)
                # ç”Ÿæˆæ–° UUID
                new_mid = str(uuid.uuid4())
                
                # åˆå§‹åŒ–æ–°ä»»åŠ¡å¯¹è±¡
                new_task = OptimizationTask(
                    mid=new_mid,
                    original_content="", # æ–°è®°å¿†åˆå§‹ä¸ºç©º
                    stats={"neg_queries": task.stats.get('neg_queries', [])}, # ç»§æ‰¿é”™é¢˜ä»¥ä¾¿é€šè¿‡æµ‹è¯•
                    expert_action="CREATE", # æ ‡è®°ä¸ºåˆ›å»ºåŠ¨ä½œ
                    is_new_node=True,
                    parent_id=task.mid
                )
                
                # æ„å»º Prompt (ç±»ä¼¼äº REPLACEï¼Œåˆ©ç”¨é”™é¢˜å’Œæ¢¯åº¦ä»å¤´å†™)
                p_new = self.cfg.optimizer.prompts.appgrad_low_replace.format(
                    neg_queries=neg_text, 
                    gradient=f"Create a NEW memory specific to these queries. Advice: {gradient}"
                )
                new_task.student_prompt = p_new
                
                # åŠ å…¥é˜Ÿåˆ—
                prompts.append(p_new)
                active_tasks.append(new_task) # æ–°ä»»åŠ¡ä¹Ÿä½œä¸º active_task æ¥æ”¶ LLM è¾“å‡º
                new_spawned_tasks.append(new_task)

            elif task.expert_action == "REPLACE":
                p = self.cfg.optimizer.prompts.appgrad_low_replace.format(neg_queries=neg_text, gradient=gradient)
                task.student_prompt = p
                prompts.append(p)
                active_tasks.append(task)

            else: # REFINE 
                p = self.cfg.optimizer.prompts.appgrad_low_refine.format(content=task.original_content, gradient=gradient)
                task.student_prompt = p
                prompts.append(p)
                active_tasks.append(task)

        if not prompts: return []

        self.log(f"âœï¸ [Student] Drafting updates for {len(prompts)} tasks (incl. expansions)...")
        
        # æ‰¹é‡è°ƒç”¨ Student (å»ºè®®ç”¨ call_llm_batch)
        outputs = call_expert_batch(prompts, self.cfg) 
        
        for t, out in zip(active_tasks, outputs):
            # æå–å†…å®¹
            clean_content = _extract_single_memory(out)
            t.generated_content = clean_content if clean_content else out
            
            # ç®€å•çš„æ—¥å¿—
            if t.is_new_node:
                self.log(f"     [NEW NODE] Generated content for {t.mid[:6]} (Parent: {t.parent_id[:6]})")

        return new_spawned_tasks

    # --------------------------------------------------------------------------
    # Phase 3: Evaluation Loop (The Generalization Guard)
    # --------------------------------------------------------------------------
    def _batch_evaluate_loop(self, tasks: List[OptimizationTask]):
        """åŒ…å« Retry çš„è¯„ä¼°å¾ªç¯"""
        
        for retry_idx in range(self.max_retries + 1):
            # 1. ç­›é€‰éœ€è¦è¯„ä¼°çš„ä»»åŠ¡ (å¿…é¡»æœ‰ç”Ÿæˆå†…å®¹ï¼Œä¸”è¿˜æ²¡PASS)
            pending_tasks = [t for t in tasks if t.judge_verdict != "PASS" and t.generated_content]
            if not pending_tasks:
                break
                
            self.log(f"âš–ï¸ [Judge] Round {retry_idx}: Evaluating {len(pending_tasks)} candidates...")
            
            # 2. æ„å»º Judge Prompts
            judge_prompts = []
            for t in pending_tasks:
                neg_q = "\n".join(t.stats.get('neg_queries', [])[:3])
                # [æ³›åŒ–æ€§æ£€æŸ¥]
                p = self.cfg.optimizer.prompts.expert_judge.format(failed = neg_q, old = t.original_content, new = t.generated_content)
                judge_prompts.append(p)
            
            # 3. è°ƒç”¨ Judge
            judge_outs = call_expert_batch(judge_prompts, self.cfg)
            
            # 4. å¤„ç†ç»“æœ & å‡†å¤‡ Retry
            retry_prompts = []
            retry_tasks = []
            
            for t, out in zip(pending_tasks, judge_outs):
                verdict_match = self.verdict_re.search(out)
                verdict = verdict_match.group(1).upper() if verdict_match else "FAIL"
                
                feedback = out.split("Feedback:")[-1].strip() if "Feedback:" in out else out[-100:]
                
                t.judge_verdict = verdict
                t.judge_feedback = feedback
                
                if verdict == "PASS":
                    t.final_accepted_content = t.generated_content
                    self.log(f"  âœ… [PASS] ID:{t.mid[:6]}")
                else:
                    self.log(f"  âŒ [FAIL] ID:{t.mid[:6]} | Feedback: {feedback[:50]}...")
                    if retry_idx < self.max_retries:
                        # æ„å»º Retry Prompt
                        new_prompt = self.cfg.optimizer.prompts.retry_prompt.format(ori = t.student_prompt, failed = neg_q, bad = t.generated_content,feedback = feedback)
                        retry_prompts.append(new_prompt)
                        retry_tasks.append(t)

            # 5. æ‰§è¡Œ Retry ç”Ÿæˆ
            if retry_prompts:
                self.log(f"ğŸ”„ [Retry] Regenerating {len(retry_prompts)} items...")
                retry_outs = call_expert_batch(retry_prompts, self.cfg)
                for t, out in zip(retry_tasks, retry_outs):
                    t.generated_content = _extract_single_memory(out) or out
                    t.retry_count += 1
            else:
                break

    # --------------------------------------------------------------------------
    # Phase 4: Commit
    # --------------------------------------------------------------------------
    def _commit_changes(self, tasks: List[OptimizationTask]) -> Set[str]:
        success_ids = set()
        for t in tasks:
            if t.final_accepted_content:
                # å†™å…¥ Memory Storage
                if t.is_new_node:
                    # ğŸ”¥ [å¤„ç† EXPAND æ–°èŠ‚ç‚¹]
                    self.memories[t.mid] = {
                        "id": t.mid,
                        "contents": t.final_accepted_content,
                        "cluster_id": -1, # ç­‰å¾…é‡æ–°èšç±»
                        "opt_type": "textgrad_expand",
                        "parent_id": t.parent_id
                    }
                    # åˆå§‹åŒ– Stats
                    self.memory_stats[t.mid] = {
                        "alpha": 0.5, 
                        "beta": 0.5, 
                        "neg_queries": [], 
                        "pos_queries": []
                    }
                    self.log(f"âœ¨ [EXPAND] Created New Node: {t.mid[:8]}")
                else:
                    # [å¤„ç† REFINE/REPLACE æ—§èŠ‚ç‚¹]
                    self.memories[t.mid]["contents"] = t.final_accepted_content
                    self.memories[t.mid]["cluster_id"] = -1 
                    self.memories[t.mid]["opt_type"] = "textgrad_v2"
                    # æ¸…ç©ºé”™é¢˜æœ¬
                    if t.mid in self.memory_stats:
                        self.memory_stats[t.mid]['neg_queries'] = []
                    self.log(f"ğŸ’¾ [UPDATE] Updated Node: {t.mid[:8]}")
                
                success_ids.add(t.mid)
        return success_ids

# ------------------------------------------------------------------------------
# å¤–éƒ¨è°ƒç”¨æ¥å£
# ------------------------------------------------------------------------------
def textgrad_opt(cfg, memories, memory_stats, log_file_path, cluster_to_ids, bad_ids, to_delete_ids):
    optimizer = TextGradOptimizer(cfg, memories, memory_stats, log_file_path)
    target_ids_list = list(bad_ids)
    return optimizer.run(target_ids_list, to_delete_ids)